{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet50",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBQzBoaY8EPEZirdnABzpR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rainmaker29/Advanced-Regression/blob/master/resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUDSTXQWndfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5ef3cdd-686f-4b64-f492-ccc666e42fee"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "BatchNormalization._USE_V2_BEHAVIOR = False\n",
        "\n",
        "# Used to make the tensorflow_addons work (Used for Group Norm Operation)\n",
        "!pip install typeguard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56DAXkUdog_E",
        "colab_type": "text"
      },
      "source": [
        "# Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS-BINpQ1P0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdditionLayer(Layer):\n",
        "  def __init__(self):\n",
        "    super(self.__class__,self).__init__()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self,input1,input2):\n",
        "    return self.add([input1,input2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBLk_JDQoLjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchNorm(Layer):\n",
        "  def __init__(self,scale=True, center=True,name=None):\n",
        "    super(self.__class__,self).__init__()\n",
        "    self.bn = BatchNormalization(scale=True,center=True,trainable=True,name=name)\n",
        "\n",
        "  @tf.function\n",
        "  def call(self,inputs,training=True):\n",
        "    return self.bn(inputs,training=training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBw4h8pSpQzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu(Layer):\n",
        "  \n",
        "  def __init__(self,name='None'):\n",
        "    super(self.__class__,self).__init__()\n",
        "    # self.relu = tf.keras.layers.Activation('relu',name=name)\n",
        "    self.relu = tf.nn.relu\n",
        "    self._name = name\n",
        "\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self,inputs):\n",
        "    return self.relu(inputs)"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72TFVQITsGxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Convolution(Layer):\n",
        "  def __init__(self,filters,kernel_size,conv_name,bn_name,padding = 'valid',stride = (1,1),use_bias = True,train_bn = True):\n",
        "    super(self.__class__,self).__init__()   \n",
        "    self.conv = tf.keras.layers.Conv2D(filters=filters, kernel_size = kernel_size,name=conv_name\n",
        "                                       , padding = padding, strides = stride,use_bias=use_bias)\n",
        "    self.bn = BatchNorm(name=bn_name)\n",
        "    self.train_bn=train_bn\n",
        "\n",
        "  @tf.function\n",
        "  def call(self,inputs):\n",
        "    x = self.conv(inputs)\n",
        "    return self.bn(x,training=self.train_bn)"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlSV8KKo109s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class conv_block(Layer):\n",
        "  def __init__(self,kernel_size,filters,stage,block,strides = (2,2),use_bias=True,train_bn=True):\n",
        "    super(self.__class__,self).__init__()\n",
        "    self.nb_filter1, self.nb_filter2, self.nb_filter3 = filters\n",
        "    self.conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    self.bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    self.strides = strides\n",
        "    self.use_bias = use_bias\n",
        "    self.train_bn = train_bn\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stage = stage\n",
        "    self.block=block\n",
        "\n",
        "  @tf.function\n",
        "  def call(self,inputs):\n",
        "    x = Convolution(filters = self.nb_filter1, kernel_size = (1,1), conv_name = self.conv_name_base + '2a', \n",
        "                    stride=self.strides ,bn_name = self.bn_name_base + '2a',use_bias=self.use_bias,train_bn=self.train_bn)(inputs)\n",
        "    x = Relu()(x)\n",
        "\n",
        "    x = Convolution(filters = self.nb_filter2, kernel_size = (self.kernel_size,self.kernel_size), conv_name = self.conv_name_base + '2b',bn_name = self.bn_name_base + '2b',padding='same',use_bias=self.use_bias,train_bn=self.train_bn)(x)\n",
        "    x = Relu()(x)\n",
        "\n",
        "    x = Convolution(filters = self.nb_filter3, kernel_size = (1,1), conv_name = self.conv_name_base + '2c', \n",
        "                    bn_name = self.bn_name_base + '2c',use_bias=self.use_bias,train_bn=self.train_bn)(x)\n",
        "    \n",
        "    shortcut = Convolution(filters = self.nb_filter3, kernel_size = (1,1), conv_name = self.conv_name_base + '1', \n",
        "                    stride=self.strides ,bn_name = self.bn_name_base + '1',use_bias=self.use_bias,train_bn=self.train_bn)(inputs)\n",
        "    \n",
        "\n",
        "    x = AdditionLayer()(x,shortcut)\n",
        "\n",
        "    x = Relu(name='res' + str(self.stage) + self.block + '_out')(x)\n",
        "\n",
        "    return x\n",
        "    "
      ],
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M8SCFohtVZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class identity_block(Layer):\n",
        "  def __init__(self,kernel_size,filters,stage,block,use_bias=True,train_bn=True):\n",
        "    super(self.__class__,self).__init__()\n",
        "    self.nb_filter1, self.nb_filter2, self.nb_filter3 = filters\n",
        "    self.conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    self.bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stage = stage\n",
        "    self.block = block\n",
        "\n",
        "  @tf.function\n",
        "  def call(self,inputs):\n",
        "    x = Convolution(filters = self.nb_filter1, kernel_size = (1,1), conv_name = self.conv_name_base + '2a', \n",
        "                    bn_name = self.bn_name_base + '2a')(inputs)\n",
        "    x = Relu()(x)\n",
        "\n",
        "    x = Convolution(filters = self.nb_filter2, kernel_size = (self.kernel_size,self.kernel_size), conv_name = self.conv_name_base + '2b', \n",
        "                    bn_name = self.bn_name_base + '2b',padding='same')(x)\n",
        "    x = Relu()(x)\n",
        "\n",
        "    x = Convolution(filters = self.nb_filter3, kernel_size = (1,1), conv_name = self.conv_name_base + '2c', \n",
        "                    bn_name = self.bn_name_base + '2c')(x)\n",
        "    x = AdditionLayer()(x,inputs)\n",
        "\n",
        "    x = Relu(name='res' + str(self.stage) + self.block + '_out')(x)\n",
        "\n",
        "    return x\n",
        "    "
      ],
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMSOAGEsDRJ-",
        "colab_type": "text"
      },
      "source": [
        "# Resnet Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMzzz8dRDQCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Resnet(Model):\n",
        "  def __init__(self,architecture,stage_5=False,train_bn=True):\n",
        "    super(self.__class__,self).__init__()\n",
        "\n",
        "    assert architecture in ['resnet50','resnet101']\n",
        "    self.C1,self.C2,self.C3,self.C4,self.C5 = None , None , None , None , None\n",
        "  \n",
        "    #stage 1\n",
        "    self.l1 = tf.keras.layers.ZeroPadding2D((3,3))\n",
        "    self.l2 = Convolution(filters=64,kernel_size=(7,7),conv_name='conv1',bn_name='conv1',use_bias=True,train_bn=True)\n",
        "    self.l3 = Relu()\n",
        "\n",
        "    self.l4 = tf.keras.layers.MaxPool2D((3,3),strides=(2,2),padding='same')\n",
        "\n",
        "    #stage 2\n",
        "    self.l5 = conv_block(kernel_size=3,filters=[64,64,256],stage=2,block='a',strides=(1,1),train_bn=train_bn)\n",
        "    self.l6 = identity_block(kernel_size=3,filters=[64,64,256],stage=2,block='b',train_bn=train_bn)\n",
        "    self.l7 = identity_block(kernel_size=3,filters=[64,64,256],stage=2,block='c',train_bn=train_bn)\n",
        "\n",
        "    #stage 3\n",
        "    self.l8 = conv_block(kernel_size=3,filters=[128,128,512],stage=3,block='a',train_bn=train_bn)\n",
        "    self.l9 = identity_block(kernel_size=3,filters=[128,128,512],stage=3,block='a',train_bn=train_bn)\n",
        "    self.l10 = identity_block(kernel_size=3,filters=[128,128,512],stage=3,block='a',train_bn=train_bn)\n",
        "    self.l11 = identity_block(kernel_size=3,filters=[128,128,512],stage=3,block='a',train_bn=train_bn)\n",
        "\n",
        "    #stage 4\n",
        "    self.l12 = conv_block(kernel_size=3,filters=[256,256,1024],stage=4,block='a',train_bn=train_bn)\n",
        "    self.block_count = {\"resnet50\": 5, \"resnet101\": 22}[architecture]\n",
        "    self.arch_wise_layers = list()\n",
        "    \n",
        "    for i in range(self.block_count):\n",
        "      self.arch_wise_layers.append(identity_block(kernel_size=3,filters=[256,256,1024],stage=4,block=chr(98 + i),train_bn=train_bn))\n",
        "    \n",
        "    #stage5\n",
        "    self.stage5=False\n",
        "    if stage_5:\n",
        "      self.stage5=True\n",
        "      \n",
        "      self.s5_l1 = conv_block(kernel_size=3,filters=[512,512,2048],stage=5,block='a',train_bn = train_bn)\n",
        "      self.s5_l2 = identity_block(kernel_size=3,filters=[512,512,2048],stage=5,block='b',train_bn = train_bn)\n",
        "      self.s5_l3 = identity_block(kernel_size=3,filters=[512,512,2048],stage=5,block='c',train_bn = train_bn)\n",
        "\n",
        "  def build(self,input_shape):\n",
        "    super(self.__class__,self).build(input_shape)\n",
        "\n",
        "  @tf.function\n",
        "  def call(self,inputs):\n",
        "    #stage 1\n",
        "    x = self.l1(inputs)\n",
        "    print('shape check')\n",
        "    print(x.shape)\n",
        "    \n",
        "    x = self.l2(x)\n",
        "\n",
        "    print('shap check')\n",
        "    print(x.shape)\n",
        "\n",
        "    x = self.l3(x)\n",
        "    print('shape check')\n",
        "    print(x.shape)\n",
        "\n",
        "    x = self.l4(x)\n",
        "    print('shape check')\n",
        "    print(x.shape)\n",
        "    self.C1 = x\n",
        "\n",
        "    #stage 2\n",
        "    x = self.l5(x)\n",
        "    print('shape check')\n",
        "    print(x.shape)\n",
        "\n",
        "    x = self.l6(x)\n",
        "    print('shape check')\n",
        "    print(x.shape)\n",
        "\n",
        "    x = self.l7(x)\n",
        "    print('shape check')\n",
        "    print(x.shape)\n",
        "\n",
        "    self.C2 = x\n",
        "\n",
        "    #stage 3\n",
        "    x = self.l8(x)\n",
        "    print('shape check')\n",
        "    print(x.shape)\n",
        "\n",
        "    x = self.l9(x)\n",
        "    print('shape check')\n",
        "    print(x.shape)\n",
        "\n",
        "    x = self.l10(x)\n",
        "    print('shape check')\n",
        "    print(x.shape)\n",
        "\n",
        "    x = self.l11(x)\n",
        "    print('shape check')\n",
        "    print(x.shape)\n",
        "\n",
        "    self.C3 = x\n",
        "\n",
        "    #stage 4\n",
        "    x = self.l12(x)\n",
        "    print('shape check')\n",
        "    print(x.shape)\n",
        "\n",
        "    # return x\n",
        "    for l in self.arch_wise_layers:\n",
        "      x = l(x)\n",
        "      print('shape-l check')\n",
        "      print(x.shape)\n",
        "    self.C4 = x\n",
        "\n",
        "    #stage 5\n",
        "    if self.stage5:\n",
        "      x = self.s5_l1(x)\n",
        "      x = self.s5_l2(x)\n",
        "      x = self.s5_l3(x)\n",
        "      self.C5 = x\n",
        "\n",
        "    print(type(x))\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N6GAjT_XN0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = Resnet('resnet50')"
      ],
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz4NS3_4rhZt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cff16ff6-9249-4d33-d7eb-5558022b2a69"
      },
      "source": [
        "s = (20, 224, 224, 3)\n",
        "nx = np.random.rand(*s).astype(np.float32)/ 255\n",
        "print(nx.shape)\n",
        "\n",
        "m._set_inputs(nx)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(nx)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=10).batch(5)\n",
        "\n",
        "indices = [0, 1, 2, 3, 4]\n",
        "depth = 14\n",
        "sample_labels = tf.one_hot(indices, depth)\n",
        "print(sample_labels.shape)"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 224, 224, 3)\n",
            "(5, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBYN0fZz_JgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnzFmjWJODHz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b0bce2b3-f952-4e66-8119-d16a1d3a602e"
      },
      "source": [
        "m.call(z)"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape check\n",
            "(20, 230, 230, 3)\n",
            "shap check\n",
            "(20, 224, 224, 64)\n",
            "shape check\n",
            "(20, 224, 224, 64)\n",
            "shape check\n",
            "(20, 112, 112, 64)\n",
            "shape check\n",
            "(20, 112, 112, 256)\n",
            "shape check\n",
            "(20, 112, 112, 256)\n",
            "shape check\n",
            "(20, 112, 112, 256)\n",
            "shape check\n",
            "(20, 56, 56, 512)\n",
            "shape check\n",
            "(20, 56, 56, 512)\n",
            "shape check\n",
            "(20, 56, 56, 512)\n",
            "shape check\n",
            "(20, 56, 56, 512)\n",
            "shape check\n",
            "(20, 28, 28, 1024)\n",
            "shape-l check\n",
            "(20, 28, 28, 1024)\n",
            "shape-l check\n",
            "(20, 28, 28, 1024)\n",
            "shape-l check\n",
            "(20, 28, 28, 1024)\n",
            "shape-l check\n",
            "(20, 28, 28, 1024)\n",
            "shape-l check\n",
            "(20, 28, 28, 1024)\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-390-47d9a49e5129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    648\u001b[0m               *args, **kwds)\n\u001b[1;32m    649\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m:  Error while reading resource variable bn4d_branch2c/beta_73253 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/bn4d_branch2c/beta_73253/N10tensorflow3VarE does not exist.\n\t [[{{node identity_block_407/StatefulPartitionedCall/convolution_2/StatefulPartitionedCall/batch_norm_2/StatefulPartitionedCall/bn4d_branch2c/ReadVariableOp_1}}]] [Op:__inference_call_74543]\n\nFunction call stack:\ncall\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMY3geJV_Mlh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9209342d-7c8b-473f-c9cd-549a2b711f5c"
      },
      "source": [
        "epochs = 2\n",
        "loss_metric = tf.keras.metrics.Mean()\n",
        "\n",
        "# Iterate over epochs.\n",
        "for epoch in range(epochs):\n",
        "    print('Start of epoch %d' % (epoch,))\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, x_batch_train in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            x = m(x_batch_train)\n",
        "            print(x.shape)\n",
        "            \n",
        "            \n",
        "            # Compute reconstruction loss\n",
        "            loss = tf.nn.softmax_cross_entropy_with_logits(logits=x, labels=sample_labels)\n",
        "            print(loss)\n",
        "\n",
        "        grads = tape.gradient(loss, m.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, m.trainable_weights))\n",
        "\n",
        "        loss_metric(loss)\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print('step %s: mean loss = %s' % (step, loss_metric.result()))\n",
        "            \n",
        "# NOTE: tf2test/MobilenetV2 is directory path, \"checkpoint\" at the end is for the name of checkpoint\n",
        "# m.save_weights('../../tf2test/MobilenetV2/MobilenetV2')"
      ],
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 0\n",
            "shape check\n",
            "(5, 230, 230, 3)\n",
            "shap check\n",
            "(5, 224, 224, 64)\n",
            "shape check\n",
            "(5, 224, 224, 64)\n",
            "shape check\n",
            "(5, 112, 112, 64)\n",
            "shape check\n",
            "(5, 112, 112, 256)\n",
            "shape check\n",
            "(5, 112, 112, 256)\n",
            "shape check\n",
            "(5, 112, 112, 256)\n",
            "shape check\n",
            "(5, 56, 56, 512)\n",
            "shape check\n",
            "(5, 56, 56, 512)\n",
            "shape check\n",
            "(5, 56, 56, 512)\n",
            "shape check\n",
            "(5, 56, 56, 512)\n",
            "shape check\n",
            "(5, 28, 28, 1024)\n",
            "shape-l check\n",
            "(5, 28, 28, 1024)\n",
            "shape-l check\n",
            "(5, 28, 28, 1024)\n",
            "shape-l check\n",
            "(5, 28, 28, 1024)\n",
            "shape-l check\n",
            "(5, 28, 28, 1024)\n",
            "shape-l check\n",
            "(5, 28, 28, 1024)\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "shape check\n",
            "(5, 230, 230, 3)\n",
            "shap check\n",
            "(5, 224, 224, 64)\n",
            "shape check\n",
            "(5, 224, 224, 64)\n",
            "shape check\n",
            "(5, 112, 112, 64)\n",
            "shape check\n",
            "(5, 112, 112, 256)\n",
            "shape check\n",
            "(5, 112, 112, 256)\n",
            "shape check\n",
            "(5, 112, 112, 256)\n",
            "shape check\n",
            "(5, 56, 56, 512)\n",
            "shape check\n",
            "(5, 56, 56, 512)\n",
            "shape check\n",
            "(5, 56, 56, 512)\n",
            "shape check\n",
            "(5, 56, 56, 512)\n",
            "shape check\n",
            "(5, 28, 28, 1024)\n",
            "shape-l check\n",
            "(5, 28, 28, 1024)\n",
            "shape-l check\n",
            "(5, 28, 28, 1024)\n",
            "shape-l check\n",
            "(5, 28, 28, 1024)\n",
            "shape-l check\n",
            "(5, 28, 28, 1024)\n",
            "shape-l check\n",
            "(5, 28, 28, 1024)\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-391-e3e21c8cf480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch_train\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m   1754\u001b[0m           \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_with_tangents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m           cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1756\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m       with ops.get_default_graph()._override_gradient_function(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m:  Error while reading resource variable res4a_branch2a/kernel_78892 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/res4a_branch2a/kernel_78892/N10tensorflow3VarE does not exist.\n\t [[{{node conv_block_122/StatefulPartitionedCall/convolution/StatefulPartitionedCall/res4a_branch2a/Conv2D/ReadVariableOp}}]] [Op:__forward_call_88973]\n\nFunction call stack:\ncall\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnXvJp7r_OYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = tf.constant(nx)"
      ],
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzshN-SibvRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}